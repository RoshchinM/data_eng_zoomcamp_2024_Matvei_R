Question 1. Data Loading
Once the dataset is loaded, what's the shape of the data?

266,855 rows x 20 columns <<<<
544,898 rows x 18 columns
544,898 rows x 20 columns
133,744 rows x 20 columns


Question 2. Data Transformation
Upon filtering the dataset where the passenger count is greater than 0 and the trip distance is greater than zero, how many rows are left?

544,897 rows
266,855 rows
139,370 rows <<<
266,856 rows

Question 3. Data Transformation
Which of the following creates a new column lpep_pickup_date by converting lpep_pickup_datetime to a date?

data = data['lpep_pickup_datetime'].date
data('lpep_pickup_date') = data['lpep_pickup_datetime'].date
data['lpep_pickup_date'] = data['lpep_pickup_datetime'].dt.date <<<<
data['lpep_pickup_date'] = data['lpep_pickup_datetime'].dt().date()

Question 4. Data Transformation
What are the existing values of VendorID in the dataset?

1, 2, or 3
1 or 2 <<<
1, 2, 3, 4
1


Question 5. Data Transformation
How many columns need to be renamed to snake case?

3
6
2
4 <<<

Question 6. Data Exporting
Once exported, how many partitions (folders) are present in Google Cloud?

96 <<<
56
67
108


1) data loader 
import io
import pandas as pd
import requests
if 'data_loader' not in globals():
    from mage_ai.data_preparation.decorators import data_loader
if 'test' not in globals():
    from mage_ai.data_preparation.decorators import test


if 'data_loader' not in globals():
    from mage_ai.data_preparation.decorators import data_loader
if 'test' not in globals():
    from mage_ai.data_preparation.decorators import test


@data_loader
def load_data(*args, **kwargs):

    urls = ['https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2020-10.csv.gz',
            'https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2020-11.csv.gz',
            'https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2020-12.csv.gz']

    taxi_dtypes = {
                'VendorID': pd.Int64Dtype(),
                'store_and_fwd_flag': str,
                'RatecodeID': pd.Int64Dtype(),
                'PULocationID':pd.Int64Dtype(),
                'DOLocationID':pd.Int64Dtype(),
                'passenger_count': pd.Int64Dtype(),
                'trip_distance': float,
                'fare_amount': float,
                'extra':float,
                'mta_tax':float,
                'tip_amount':float,
                'tolls_amount':float,
                'ehail_fee': float,
                'improvement_surcharge':float,
                'total_amount':float,
                'payment_type': pd.Int64Dtype(),
                'trip_type': pd.Int64Dtype(),
                'congestion_surcharge':float
    }

    parse_dates = ['lpep_pickup_datetime', 'lpep_dropoff_datetime']

    dfs = []
    for url in urls:
        df = pd.read_csv(url, sep=",", compression='gzip', dtype=taxi_dtypes, parse_dates=parse_dates)
        dfs.append(df)


    return pd.concat(dfs, ignore_index=True)


@test
def test_output(output, *args) -> None:
    """
    Template code for testing the output of the block.
    """
    assert output is not None, 'The output is undefined'


2) data Transformation
if 'transformer' not in globals():
    from mage_ai.data_preparation.decorators import transformer
if 'test' not in globals():
    from mage_ai.data_preparation.decorators import test


@transformer
def transform(data, *args, **kwargs):
# 1 фильтр на каунт пассажиров
    print("Rows with zero passengers:",data['passenger_count'].isin([0]).sum())

# 2 фильтр на снейккейс
    data.columns = (data.columns
                    .str.replace(' ', '_')
                    .str.lower()
    )
# 3 изменение на новую колонку с датой
    data['lpep_pickup_date']=data['lpep_pickup_datetime'].dt.date


# 4 фильтр на трип дистанс
    data = data[data['trip_distance'] > 0]

    return data[data['passenger_count']>0]

@test
def test_output(output, *args) -> None:
    """
    Template code for testing the output of the block.
    """
    assert output is not None, 'The output is undefined'
    
        # Print column names
    #print("Column Names:", output.columns)
    
    valid_vendor_ids = [1, 2]  # Замените на реальные существующие значения
    assert all(output['vendorid'].isin(valid_vendor_ids)), 'Invalid vendor_id values'

    assert (output['passenger_count'] > 0).all(), 'passenger_count should be greater than 0'
    assert (output['trip_distance'] > 0).all(), 'trip_distance should be greater than 0'
 

3) data export to local 
from mage_ai.settings.repo import get_repo_path
from mage_ai.io.config import ConfigFileLoader
from mage_ai.io.postgres import Postgres
from pandas import DataFrame
from os import path

if 'data_exporter' not in globals():
    from mage_ai.data_preparation.decorators import data_exporter


@data_exporter
def export_data_to_postgres(df: DataFrame, **kwargs) -> None:
    """
    Template for exporting data to a PostgreSQL database.
    Specify your configuration settings in 'io_config.yaml'.

    Docs: https://docs.mage.ai/design/data-loading#postgresql
    """
    schema_name = 'ny_taxi'  # Specify the name of the schema to export data to
    table_name = 'green_cab_data'  # Specify the name of the table to export data to
    config_path = path.join(get_repo_path(), 'io_config.yaml')
    config_profile = 'dev'

    with Postgres.with_config(ConfigFileLoader(config_path, config_profile)) as loader:
        loader.export(
            df,
            schema_name,
            table_name,
            index=False,  # Specifies whether to include index in exported table
            if_exists='replace',  # Specify resolution policy if table name already exists
        )


4) data export to gcp

from mage_ai.settings.repo import get_repo_path
from mage_ai.io.config import ConfigFileLoader
from mage_ai.io.google_cloud_storage import GoogleCloudStorage
from pandas import DataFrame
from os import path

if 'data_exporter' not in globals():
    from mage_ai.data_preparation.decorators import data_exporter


@data_exporter
def export_data_to_google_cloud_storage(df: DataFrame, **kwargs) -> None:
    """
    Template for exporting data to a Google Cloud Storage bucket.
    Specify your configuration settings in 'io_config.yaml'.

    Docs: https://docs.mage.ai/design/data-loading#googlecloudstorage
    """
    config_path = path.join(get_repo_path(), 'io_config.yaml')
    config_profile = 'default'

    bucket_name = 'mage-zoompamp-matvei-roshchin'
    object_key = 'green_taxi_date.parquet'

    GoogleCloudStorage.with_config(ConfigFileLoader(config_path, config_profile)).export(
        df,
        bucket_name,
        object_key,
    )

5) data export to gcp by forlders parquet 
import pyarrow as pa
import pyarrow.parquet as pq
import os


if 'data_exporter' not in globals():
    from mage_ai.data_preparation.decorators import data_exporter

os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = "/home/src/taxy-rides-ny-412222-936e7cd28ed4.json"

bucket_name = 'mage-zoompamp-matvei-roshchin'
project_id = 'taxy-rides-ny-412222'

table_name = "green_cab_data"

root_path = f'{bucket_name}/{table_name}'

@data_exporter
def export_data(data, *args, **kwargs):
    data['lpep_pickup_date'] =data['lpep_pickup_datetime'].dt.date

    table = pa.Table.from_pandas(data)

    gcs = pa.fs.GcsFileSystem()

    pq.write_to_dataset(
        table,
        root_path,
        partition_cols=['lpep_pickup_date'],
        filesystem=gcs
    ) 